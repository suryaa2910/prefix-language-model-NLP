{
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 13459.163797,
      "end_time": "2024-01-20T21:31:11.029816",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-20T17:46:51.866019",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryaa2910/prefix-language-model-NLP/blob/main/prefix%20language%20model%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zocket_Suryaa_Task 2:**\n",
        "\n",
        "**Problem Statement:**\n",
        "Develop a prefix language model using Hugging Face and PyTorch. You can pick any dataset for a creative text generation task and you should report the perplexity metric. Hint: A subtle data preprocessing trick is required when setting the inputs and labels for implementing prefix LM.\n",
        "\n",
        "**Model Selected:** t5-large\n",
        "\n",
        "**Dataset Selected:** CNN daily mail"
      ],
      "metadata": {
        "id": "esvN08agdyAS"
      },
      "id": "esvN08agdyAS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation of Required Packages"
      ],
      "metadata": {
        "id": "aOgP-D4meDLY"
      },
      "id": "aOgP-D4meDLY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.36.2\n",
        "!pip install accelerate==0.25.0\n",
        "!pip install datasets==2.15.0\n",
        "!pip install peft==0.7.1\n",
        "!pip install bitsandbytes==0.41.3\n",
        "!pip install trl==0.7.7\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install flash-attn==2.4.2"
      ],
      "metadata": {
        "papermill": {
          "duration": 136.307628,
          "end_time": "2024-01-20T17:49:14.436676",
          "exception": false,
          "start_time": "2024-01-20T17:46:58.129048",
          "status": "completed"
        },
        "tags": [],
        "id": "34d1775b",
        "outputId": "52445173-c402-417e-d50b-cd8a1f7d623d",
        "execution": {
          "iopub.status.busy": "2024-03-25T04:16:55.138307Z",
          "iopub.execute_input": "2024-03-25T04:16:55.138999Z",
          "iopub.status.idle": "2024-03-25T04:19:09.460461Z",
          "shell.execute_reply.started": "2024-03-25T04:16:55.138961Z",
          "shell.execute_reply": "2024-03-25T04:19:09.459325Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting transformers==4.36.2\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.36.2) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (2024.2.2)\nDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\nSuccessfully installed transformers-4.36.2\nCollecting accelerate==0.25.0\n  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (0.21.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.25.0) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (2024.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.25.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.25.0) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\nDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.28.0\n    Uninstalling accelerate-0.28.0:\n      Successfully uninstalled accelerate-0.28.0\nSuccessfully installed accelerate-0.25.0\nCollecting datasets==2.15.0\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15.0)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.15.0)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (2024.2.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.15.0)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.0\n    Uninstalling fsspec-2024.3.0:\n      Successfully uninstalled fsspec-2024.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\nCollecting peft==0.7.1\n  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (4.36.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (0.25.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (0.4.2)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (0.21.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.7.1) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.7.1) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.7.1) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.7.1) (1.3.0)\nDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.7.1\nCollecting bitsandbytes==0.41.3\n  Downloading bitsandbytes-0.41.3-py3-none-any.whl.metadata (9.8 kB)\nDownloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.41.3\nCollecting trl==0.7.7\n  Downloading trl-0.7.7-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (4.36.2)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (0.25.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (2.15.0)\nCollecting tyro>=0.5.11 (from trl==0.7.7)\n  Downloading tyro-0.7.3-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (2023.10.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (0.21.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (4.66.1)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.7) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.7) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.7)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.7.7) (5.9.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (11.0.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (0.6)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (0.70.15)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.7.7) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.7) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.7) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.7.7) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.7) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.7) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.7) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.7.7) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.7) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.7) (1.16.0)\nDownloading trl-0.7.7-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.7.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.7.7 tyro-0.7.3\nRequirement already satisfied: tqdm==4.66.1 in /opt/conda/lib/python3.10/site-packages (4.66.1)\nCollecting flash-attn==2.4.2\n  Downloading flash_attn-2.4.2.tar.gz (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (2.1.2)\nCollecting einops (from flash-attn==2.4.2)\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (1.11.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->flash-attn==2.4.2) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (2023.10.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.4.2) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.4.2) (1.3.0)\nDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113715733 sha256=04e3db4e507c133eec26d814c9bec16ca24f8b4bef3e37c6101f2059080eccee\n  Stored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\nSuccessfully built flash-attn\nInstalling collected packages: einops, flash-attn\nSuccessfully installed einops-0.7.0 flash-attn-2.4.2\n",
          "output_type": "stream"
        }
      ],
      "id": "34d1775b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "xFpt4baqeGZs"
      },
      "id": "xFpt4baqeGZs"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments,BartTokenizer, BartForConditionalGeneration"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 1.367331,
          "end_time": "2024-01-20T17:46:58.120676",
          "exception": false,
          "start_time": "2024-01-20T17:46:56.753345",
          "status": "completed"
        },
        "tags": [],
        "id": "f3dea5c4",
        "execution": {
          "iopub.status.busy": "2024-03-25T04:19:16.201020Z",
          "iopub.execute_input": "2024-03-25T04:19:16.201388Z",
          "iopub.status.idle": "2024-03-25T04:19:35.683699Z",
          "shell.execute_reply.started": "2024-03-25T04:19:16.201355Z",
          "shell.execute_reply": "2024-03-25T04:19:35.682847Z"
        },
        "trusted": true,
        "outputId": "da6e6340-78a4-454b-ef65-497121a1cd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-03-25 04:19:26.266518: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-25 04:19:26.266616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-25 04:19:26.460208: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "id": "f3dea5c4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentication and Configuration\n",
        "> Huggingface and wandb integration"
      ],
      "metadata": {
        "id": "j6st0t0leIp-"
      },
      "id": "j6st0t0leIp-"
    },
    {
      "cell_type": "code",
      "source": [
        "user_secrets = UserSecretsClient()\n",
        "\n",
        "login(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN_2\"))\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY_2\")\n",
        "os.environ[\"WANDB_PROJECT\"] = \"Prefix language modelling\"\n",
        "os.environ[\"WANDB_NOTES\"] = \"Prefix language modelling using LORA\"\n",
        "os.environ[\"WANDB_NAME\"] = \"Prefix tuning\"\n",
        "os.environ[\"MODEL_NAME\"] = \"t5-large\""
      ],
      "metadata": {
        "papermill": {
          "duration": 1.111731,
          "end_time": "2024-01-20T17:49:15.568820",
          "exception": false,
          "start_time": "2024-01-20T17:49:14.457089",
          "status": "completed"
        },
        "tags": [],
        "id": "ea872b88",
        "outputId": "045c0b44-3c65-4356-e2df-17d9b42ac699",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:09:48.289356Z",
          "iopub.execute_input": "2024-03-25T08:09:48.289736Z",
          "iopub.status.idle": "2024-03-25T08:09:48.795932Z",
          "shell.execute_reply.started": "2024-03-25T08:09:48.289706Z",
          "shell.execute_reply": "2024-03-25T08:09:48.794957Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n",
          "output_type": "stream"
        }
      ],
      "id": "ea872b88"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accelerate Memory Estimation\n",
        "> This command estimates the memory requirements for the specified model using the Accelerate library."
      ],
      "metadata": {
        "id": "iu65KpNFeR3-"
      },
      "id": "iu65KpNFeR3-"
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate estimate-memory ${MODEL_NAME} --library_name transformers"
      ],
      "metadata": {
        "papermill": {
          "duration": 8.468262,
          "end_time": "2024-01-20T17:49:46.754709",
          "exception": false,
          "start_time": "2024-01-20T17:49:38.286447",
          "status": "completed"
        },
        "tags": [],
        "id": "8e3453f8",
        "outputId": "871e4b19-51d2-427c-e4c0-76c3ab69424e",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:09:52.416006Z",
          "iopub.execute_input": "2024-03-25T08:09:52.416875Z",
          "iopub.status.idle": "2024-03-25T08:09:59.907253Z",
          "shell.execute_reply.started": "2024-03-25T08:09:52.416841Z",
          "shell.execute_reply": "2024-03-25T08:09:59.905988Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading pretrained config for `t5-large` from `transformers`...\n┌────────────────────────────────────────────────────┐\n│        Memory Usage for loading `t5-large`         │\n├───────┬─────────────┬──────────┬───────────────────┤\n│ dtype │Largest Layer│Total Size│Training using Adam│\n├───────┼─────────────┼──────────┼───────────────────┤\n│float32│   125.5 MB  │ 2.75 GB  │      10.99 GB     │\n│float16│   62.75 MB  │ 1.37 GB  │       5.5 GB      │\n│  int8 │   31.38 MB  │ 703.5 MB │      2.75 GB      │\n│  int4 │   15.69 MB  │351.75 MB │      1.37 GB      │\n└───────┴─────────────┴──────────┴───────────────────┘\n",
          "output_type": "stream"
        }
      ],
      "id": "8e3453f8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Quantization Configuration\n",
        "> configures model quantization settings, including whether to load in 4-bit, the quantization type, and data types."
      ],
      "metadata": {
        "id": "kXhSELvOeX77"
      },
      "id": "kXhSELvOeX77"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "from accelerate import Accelerator\n",
        "import torch\n",
        "\n",
        "load_in_4bit = True\n",
        "\n",
        "if load_in_4bit:\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=load_in_4bit,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16  # Change to torch.float16 for fp16\n",
        "    )\n",
        "    # copy the model to each device\n",
        "    device_map = \"auto\"\n",
        "    torch_dtype = torch.float16  # Change to torch.float16 for fp16\n",
        "else:\n",
        "    device_map = None\n",
        "    quantization_config = None\n",
        "    torch_dtype = None"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.034222,
          "end_time": "2024-01-20T17:49:46.810623",
          "exception": false,
          "start_time": "2024-01-20T17:49:46.776401",
          "status": "completed"
        },
        "tags": [],
        "id": "6a678a90",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:03.609822Z",
          "iopub.execute_input": "2024-03-25T08:10:03.610934Z",
          "iopub.status.idle": "2024-03-25T08:10:03.620880Z",
          "shell.execute_reply.started": "2024-03-25T08:10:03.610892Z",
          "shell.execute_reply": "2024-03-25T08:10:03.619838Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "6a678a90"
    },
    {
      "cell_type": "markdown",
      "source": [
        " Loading Dataset"
      ],
      "metadata": {
        "id": "UFW2LUYVeeen"
      },
      "id": "UFW2LUYVeeen"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('cnn_dailymail','3.0.0',split='train')"
      ],
      "metadata": {
        "papermill": {
          "duration": 44.34289,
          "end_time": "2024-01-20T17:50:31.174603",
          "exception": false,
          "start_time": "2024-01-20T17:49:46.831713",
          "status": "completed"
        },
        "tags": [],
        "id": "369b16cb",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:08.811973Z",
          "iopub.execute_input": "2024-03-25T08:10:08.812719Z",
          "iopub.status.idle": "2024-03-25T08:10:16.948783Z",
          "shell.execute_reply.started": "2024-03-25T08:10:08.812684Z",
          "shell.execute_reply": "2024-03-25T08:10:16.947664Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "369b16cb"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.032826,
          "end_time": "2024-01-20T17:50:31.229863",
          "exception": false,
          "start_time": "2024-01-20T17:50:31.197037",
          "status": "completed"
        },
        "tags": [],
        "id": "d7a8765f",
        "outputId": "3ad0b16b-5f60-4c4d-fa74-2c096ad5bdd9",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:21.017598Z",
          "iopub.execute_input": "2024-03-25T08:10:21.017994Z",
          "iopub.status.idle": "2024-03-25T08:10:21.028158Z",
          "shell.execute_reply.started": "2024-03-25T08:10:21.017965Z",
          "shell.execute_reply": "2024-03-25T08:10:21.026772Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 57,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['article', 'highlights', 'id'],\n    num_rows: 287113\n})"
          },
          "metadata": {}
        }
      ],
      "id": "d7a8765f"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= dataset.shuffle(seed=42).select([i for i in range(85000)])"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.687188,
          "end_time": "2024-01-20T17:50:31.939574",
          "exception": false,
          "start_time": "2024-01-20T17:50:31.252386",
          "status": "completed"
        },
        "tags": [],
        "id": "4c5c695e",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:25.871814Z",
          "iopub.execute_input": "2024-03-25T08:10:25.872673Z",
          "iopub.status.idle": "2024-03-25T08:10:26.283965Z",
          "shell.execute_reply.started": "2024-03-25T08:10:25.872638Z",
          "shell.execute_reply": "2024-03-25T08:10:26.282776Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "4c5c695e"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(test_size=0.1,seed=42)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.126993,
          "end_time": "2024-01-20T17:50:32.089935",
          "exception": false,
          "start_time": "2024-01-20T17:50:31.962942",
          "status": "completed"
        },
        "tags": [],
        "id": "c18b757e",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:28.707950Z",
          "iopub.execute_input": "2024-03-25T08:10:28.708707Z",
          "iopub.status.idle": "2024-03-25T08:10:28.726837Z",
          "shell.execute_reply.started": "2024-03-25T08:10:28.708669Z",
          "shell.execute_reply": "2024-03-25T08:10:28.725906Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "c18b757e"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031687,
          "end_time": "2024-01-20T17:50:32.144555",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.112868",
          "status": "completed"
        },
        "tags": [],
        "id": "12b4e374",
        "outputId": "5c79c0a5-7973-45c2-f4f3-af03898afa13",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:31.909439Z",
          "iopub.execute_input": "2024-03-25T08:10:31.910139Z",
          "iopub.status.idle": "2024-03-25T08:10:31.918086Z",
          "shell.execute_reply.started": "2024-03-25T08:10:31.910101Z",
          "shell.execute_reply": "2024-03-25T08:10:31.916915Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 60,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 76500\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 8500\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "id": "12b4e374"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "\n",
        "device = \"cuda\"\n",
        "model_name_or_path = \"t5-large\"\n",
        "tokenizer_name_or_path = \"t5-large\"\n",
        "\n",
        "text_column = \"article\"\n",
        "label_column = \"highlights\"\n",
        "max_length = 256\n",
        "lr = 1e-5\n",
        "num_epochs = 1\n",
        "batch_size = 8"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.03122,
          "end_time": "2024-01-20T17:50:32.197998",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.166778",
          "status": "completed"
        },
        "tags": [],
        "id": "a72c4a11",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:35.883785Z",
          "iopub.execute_input": "2024-03-25T08:10:35.884150Z",
          "iopub.status.idle": "2024-03-25T08:10:35.891732Z",
          "shell.execute_reply.started": "2024-03-25T08:10:35.884114Z",
          "shell.execute_reply": "2024-03-25T08:10:35.890536Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "a72c4a11"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Preprocessing"
      ],
      "metadata": {
        "id": "0dkiP7aReh7b"
      },
      "id": "0dkiP7aReh7b"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[text_column]\n",
        "    targets = examples[label_column]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    labels = tokenizer(targets, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    labels = labels[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    return model_inputs"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.751841,
          "end_time": "2024-01-20T17:50:32.972637",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.220796",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "3da27ce917784243a5f44a1390178a98",
            "d963e19dc8ed4bd39bb60f27664d1dcb"
          ]
        },
        "id": "75238bc8",
        "outputId": "02fba73c-8826-424b-cffd-f05296076f0f",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:40.335318Z",
          "iopub.execute_input": "2024-03-25T08:10:40.336205Z",
          "iopub.status.idle": "2024-03-25T08:10:40.919733Z",
          "shell.execute_reply.started": "2024-03-25T08:10:40.336170Z",
          "shell.execute_reply": "2024-03-25T08:10:40.918468Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "id": "75238bc8"
    },
    {
      "cell_type": "code",
      "source": [
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 339.487833,
          "end_time": "2024-01-20T17:56:12.484479",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.996646",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "e3dc2a77cf9e46688f7848be666c4e37",
            "1a0d386514c54700a100a7a3b11c68d0",
            "0bc24d7af162448d94cdf4a3b217789c",
            "e5ee88d15be440de91c2fb85604a89c7"
          ]
        },
        "id": "2d340ac8",
        "outputId": "42817a3a-e5ab-4530-fdd8-2e492b4137c9",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:10:45.740122Z",
          "iopub.execute_input": "2024-03-25T08:10:45.740884Z",
          "iopub.status.idle": "2024-03-25T08:16:49.108778Z",
          "shell.execute_reply.started": "2024-03-25T08:10:45.740833Z",
          "shell.execute_reply": "2024-03-25T08:16:49.107665Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running tokenizer on dataset:   0%|          | 0/76500 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bc24d7af162448d94cdf4a3b217789c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Running tokenizer on dataset:   0%|          | 0/8500 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5ee88d15be440de91c2fb85604a89c7"
            }
          },
          "metadata": {}
        }
      ],
      "id": "2d340ac8"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import default_data_collator"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031576,
          "end_time": "2024-01-20T17:56:12.540626",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.509050",
          "status": "completed"
        },
        "tags": [],
        "id": "9d0aa9d4",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:16:55.026417Z",
          "iopub.execute_input": "2024-03-25T08:16:55.027245Z",
          "iopub.status.idle": "2024-03-25T08:16:55.033030Z",
          "shell.execute_reply.started": "2024-03-25T08:16:55.027213Z",
          "shell.execute_reply": "2024-03-25T08:16:55.031564Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "9d0aa9d4"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"test\"]\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        ")\n",
        "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.032596,
          "end_time": "2024-01-20T17:56:12.597034",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.564438",
          "status": "completed"
        },
        "tags": [],
        "id": "686b5ebd",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:16:59.525693Z",
          "iopub.execute_input": "2024-03-25T08:16:59.526056Z",
          "iopub.status.idle": "2024-03-25T08:16:59.533261Z",
          "shell.execute_reply.started": "2024-03-25T08:16:59.526026Z",
          "shell.execute_reply": "2024-03-25T08:16:59.532269Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "686b5ebd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefix Language Model Configuration\n",
        "> Since we are doing Text summarization task, we will use **AutoModelForSeq2SeqLM**"
      ],
      "metadata": {
        "id": "Ee4k5fqSeuLu"
      },
      "id": "Ee4k5fqSeuLu"
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.031131,
          "end_time": "2024-01-20T17:56:12.651524",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.620393",
          "status": "completed"
        },
        "tags": [],
        "id": "08e3516d",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:17:05.422226Z",
          "iopub.execute_input": "2024-03-25T08:17:05.423010Z",
          "iopub.status.idle": "2024-03-25T08:17:05.429046Z",
          "shell.execute_reply.started": "2024-03-25T08:17:05.422974Z",
          "shell.execute_reply": "2024-03-25T08:17:05.427801Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "08e3516d"
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=20)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "papermill": {
          "duration": 17.387135,
          "end_time": "2024-01-20T17:56:30.062217",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.675082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "2322dd73c7e342c4850c545f8af7b244",
            "aa514efe720240c89cc1a2d4b4438749"
          ]
        },
        "id": "23ca1fec",
        "outputId": "fd0ba740-7fbe-4a39-8e39-74edd10770be",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:17:10.121934Z",
          "iopub.execute_input": "2024-03-25T08:17:10.122270Z",
          "iopub.status.idle": "2024-03-25T08:17:12.313527Z",
          "shell.execute_reply.started": "2024-03-25T08:17:10.122243Z",
          "shell.execute_reply": "2024-03-25T08:17:12.312341Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 983,040 || all params: 738,651,136 || trainable%: 0.13308583065659835\n",
          "output_type": "stream"
        }
      ],
      "id": "23ca1fec"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.050008,
          "end_time": "2024-01-20T17:56:30.141488",
          "exception": false,
          "start_time": "2024-01-20T17:56:30.091480",
          "status": "completed"
        },
        "tags": [],
        "id": "718cad56",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:17:16.919753Z",
          "iopub.execute_input": "2024-03-25T08:17:16.920602Z",
          "iopub.status.idle": "2024-03-25T08:17:16.926605Z",
          "shell.execute_reply.started": "2024-03-25T08:17:16.920567Z",
          "shell.execute_reply": "2024-03-25T08:17:16.925454Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "718cad56"
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.050613,
          "end_time": "2024-01-20T17:56:30.220885",
          "exception": false,
          "start_time": "2024-01-20T17:56:30.170272",
          "status": "completed"
        },
        "tags": [],
        "id": "1645a46e",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:17:22.017732Z",
          "iopub.execute_input": "2024-03-25T08:17:22.018092Z",
          "iopub.status.idle": "2024-03-25T08:17:22.031801Z",
          "shell.execute_reply.started": "2024-03-25T08:17:22.018066Z",
          "shell.execute_reply": "2024-03-25T08:17:22.030905Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "1645a46e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer Initialization and Training"
      ],
      "metadata": {
        "id": "4ONaOXIie71J"
      },
      "id": "4ONaOXIie71J"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./output\",\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    save_steps=len(train_dataloader),\n",
        "    save_total_limit=5,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=lr,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=len(train_dataloader),\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=len(train_dataloader),\n",
        "    load_best_model_at_end=True,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# Create the Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=default_data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print the results\n",
        "print(results)"
      ],
      "metadata": {
        "papermill": {
          "duration": 12874.516015,
          "end_time": "2024-01-20T21:31:04.761031",
          "exception": false,
          "start_time": "2024-01-20T17:56:30.245016",
          "status": "completed"
        },
        "tags": [],
        "id": "9dd620fa",
        "outputId": "69efeeb2-1358-4648-fafb-3ef7d765d362",
        "execution": {
          "iopub.status.busy": "2024-03-25T04:30:43.563912Z",
          "iopub.execute_input": "2024-03-25T04:30:43.564282Z",
          "iopub.status.idle": "2024-03-25T07:40:22.270229Z",
          "shell.execute_reply.started": "2024-03-25T04:30:43.564250Z",
          "shell.execute_reply": "2024-03-25T07:40:22.268329Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msuryaa2910\u001b[0m (\u001b[33msuryaa2910_\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.4"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240325_043047-c1s1u615</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/suryaa2910_/Prefix%20language%20modelling/runs/c1s1u615' target=\"_blank\">Prefix tuning</a></strong> to <a href='https://wandb.ai/suryaa2910_/Prefix%20language%20modelling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/suryaa2910_/Prefix%20language%20modelling' target=\"_blank\">https://wandb.ai/suryaa2910_/Prefix%20language%20modelling</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/suryaa2910_/Prefix%20language%20modelling/runs/c1s1u615' target=\"_blank\">https://wandb.ai/suryaa2910_/Prefix%20language%20modelling/runs/c1s1u615</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='4782' max='4782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4782/4782 2:56:41, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [532/532 12:12]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 2.9073822498321533, 'eval_runtime': 734.357, 'eval_samples_per_second': 11.575, 'eval_steps_per_second': 0.724, 'epoch': 1.0}\n",
          "output_type": "stream"
        }
      ],
      "id": "9dd620fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity Calculation"
      ],
      "metadata": {
        "id": "rps4xWwZe-IK"
      },
      "id": "rps4xWwZe-IK"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def perplexity(eval_output):\n",
        "    return np.exp(eval_output)"
      ],
      "metadata": {
        "id": "H175jOpz07Rl",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:22:33.320103Z",
          "iopub.execute_input": "2024-03-25T08:22:33.321008Z",
          "iopub.status.idle": "2024-03-25T08:22:33.326441Z",
          "shell.execute_reply.started": "2024-03-25T08:22:33.320971Z",
          "shell.execute_reply": "2024-03-25T08:22:33.325261Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "H175jOpz07Rl"
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity(results['eval_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVxUG7VA3MJd",
        "outputId": "81df8961-c039-4ccf-e199-eb55e8530fe3",
        "execution": {
          "iopub.status.busy": "2024-03-25T08:22:36.219391Z",
          "iopub.execute_input": "2024-03-25T08:22:36.220152Z",
          "iopub.status.idle": "2024-03-25T08:22:36.228191Z",
          "shell.execute_reply.started": "2024-03-25T08:22:36.220118Z",
          "shell.execute_reply": "2024-03-25T08:22:36.227099Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 76,
          "output_type": "execute_result",
          "data": {
            "text/plain": "18.30880789568708"
          },
          "metadata": {}
        }
      ],
      "id": "ZVxUG7VA3MJd"
    }
  ]
}